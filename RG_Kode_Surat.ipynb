{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVEEUDNF6J+WzQxYuA/IXI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jendra-webapp/a219-mfwde-labs/blob/master/RG_Kode_Surat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaxziYRhI47O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from googleapiclient.discovery import build\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "-X5TEeRqJCPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = '11KzKA69_gEHUfRfSfDc3PgoCjezLBGMh'\n",
        "\n",
        "# Create a Google Drive API client\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# Download the file from Google Drive\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "response = request.execute()\n",
        "\n",
        "# Read the file content into a pandas DataFrame\n",
        "try:\n",
        "    df = pd.read_excel(io.BytesIO(response))\n",
        "    print(df)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHIVBPAsJFeD",
        "outputId": "6fa4b2c2-37f9-486b-af94-23ec813085af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     kelompok                                               kode  \\\n",
            "0         624                                KM.01.00 - Beasiswa   \n",
            "1         624                                KM.01.00 - Beasiswa   \n",
            "2         624                                KM.01.00 - Beasiswa   \n",
            "3         624                                KM.01.00 - Beasiswa   \n",
            "4         932                            HK.06.00 - Dalam Negeri   \n",
            "..        ...                                                ...   \n",
            "148      1192  KP.06.00 - Tugas Belajar/Ijin Belajar/ Diklat/...   \n",
            "149       980  TU.01.00 - Rapat Staf (Undangan, Daftar hadir,...   \n",
            "150       950         HK.11 - Perizinan (perizinan non akademik)   \n",
            "151       950         HK.11 - Perizinan (perizinan non akademik)   \n",
            "152       950         HK.11 - Perizinan (perizinan non akademik)   \n",
            "\n",
            "                                               perihal  \n",
            "0    FINANCIAL GUARANTEE UNTUK MENDAPATKAN BEASISWA...  \n",
            "1    FINANCIAL GUARANTEE UNTUK MENDAPATKAN BEASISWA...  \n",
            "2    FINANCIAL GUARANTEE UNTUK MENDAPATKAN BEASISWA...  \n",
            "3    FINANCIAL GUARANTEE UNTUK MENDAPATKAN BEASISWA...  \n",
            "4    PERJANJIAN TUGAS BELAJAR ANTARA UNY DENGAN DYN...  \n",
            "..                                                 ...  \n",
            "148  Permohonan Penggantian Biaya Pendaftaran a.n Y...  \n",
            "149                                     Undangan rapat  \n",
            "150  Pendampingan pengawasan dan pengendalian izin ...  \n",
            "151  Pendampingan pengawasan dan pengendalian izin ...  \n",
            "152              Laporan Jumlah Volume/Debit Air Tanah  \n",
            "\n",
            "[153 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPROSESING DATA"
      ],
      "metadata": {
        "id": "w4WYdRs7JSQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'perihal' data to lowercase\n",
        "df['perihal'] = df['perihal'].str.lower()\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(df['perihal'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4PK15ifJJRQ",
        "outputId": "e90352c6-d27e-4e4c-db08-54d47a0e487f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      financial guarantee untuk mendapatkan beasiswa...\n",
            "1      financial guarantee untuk mendapatkan beasiswa...\n",
            "2      financial guarantee untuk mendapatkan beasiswa...\n",
            "3      financial guarantee untuk mendapatkan beasiswa...\n",
            "4      perjanjian tugas belajar antara uny dengan dyn...\n",
            "                             ...                        \n",
            "148    permohonan penggantian biaya pendaftaran a.n y...\n",
            "149                                       undangan rapat\n",
            "150    pendampingan pengawasan dan pengendalian izin ...\n",
            "151    pendampingan pengawasan dan pengendalian izin ...\n",
            "152                laporan jumlah volume/debit air tanah\n",
            "Name: perihal, Length: 153, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clear text\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "def clear_text(text):\n",
        "    # Regular expression pattern to match Roman numerals\n",
        "    roman_pattern = r'\\b(?:i[vx]|v?i{0,3}|x[lc]|l?x{0,3}|c[dm]|d?c{0,3}|m{0,3})\\b'\n",
        "\n",
        "    # Use re.sub to remove the Roman numerals from the text\n",
        "    cleaned_text = re.sub(roman_pattern, '', text)\n",
        "\n",
        "    # Clear tags HTML\n",
        "    soup = BeautifulSoup(cleaned_text, 'html.parser')\n",
        "    cleaned_text = soup.get_text()\n",
        "\n",
        "    # Clear numbers\n",
        "    number_pattern = r'\\b\\d+\\b'\n",
        "    cleaned_text = re.sub(number_pattern, '', cleaned_text)\n",
        "\n",
        "    # Regular expression pattern to match special characters (anything that is not an alphabet letter or a digit)\n",
        "    special_char_pattern = r'[^a-zA-Z0-9\\s]'\n",
        "\n",
        "    # Use re.sub to remove the special characters from the text\n",
        "    cleaned_text = re.sub(special_char_pattern, '', cleaned_text)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "# Apply the clear_text function to the 'perihal' column in the DataFrame\n",
        "df['perihal'] = df['perihal'].apply(clear_text)\n",
        "\n",
        "print(df['perihal'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5xYDj0-Jb9z",
        "outputId": "a89d8fe1-eded-4d33-cbf2-5307921ba468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      financial guarantee untuk mendapatkan beasiswa...\n",
            "1      financial guarantee untuk mendapatkan beasiswa...\n",
            "2      financial guarantee untuk mendapatkan beasiswa...\n",
            "3      financial guarantee untuk mendapatkan beasiswa...\n",
            "4      perjanjian tugas belajar antara uny dengan dyn...\n",
            "                             ...                        \n",
            "148    permohonan penggantian biaya pendaftaran an ya...\n",
            "149                                       undangan rapat\n",
            "150    pendampingan pengawasan dan pengendalian izin ...\n",
            "151    pendampingan pengawasan dan pengendalian izin ...\n",
            "152                 laporan jumlah volumedebit air tanah\n",
            "Name: perihal, Length: 153, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-923c6b8cb7dd>:15: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(cleaned_text, 'html.parser')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique values in the 'perihal' column\n",
        "unique_perihal = df['perihal'].unique()\n",
        "\n",
        "\n",
        "# Update the original DataFrame to keep only the rows with unique 'perihal' values\n",
        "df.drop_duplicates(subset='perihal', keep='first', inplace=True)\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(df['perihal'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdrvk4ySJocn",
        "outputId": "f80e23d0-2fff-413e-a5fe-2b27baa046c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      financial guarantee untuk mendapatkan beasiswa...\n",
            "4      perjanjian tugas belajar antara uny dengan dyn...\n",
            "5      surat rekomendasi untuk tugas belajar di notti...\n",
            "6      pelaksanaan program ppg dalam jabatan bersubsi...\n",
            "8      perjanjian kerjasama antara badan kepegawaian ...\n",
            "                             ...                        \n",
            "146    st melaksanakan pembersihan lingkungan dan rua...\n",
            "147    permohonan penggantian biaya pendaftaran an si...\n",
            "148    permohonan penggantian biaya pendaftaran an ya...\n",
            "150    pendampingan pengawasan dan pengendalian izin ...\n",
            "152                 laporan jumlah volumedebit air tanah\n",
            "Name: perihal, Length: 123, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kata dasar\n",
        "!pip install sastrawi\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "# Download necessary resources for the NLTK library\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Create the Sastrawi stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcStnz1QJufc",
        "outputId": "8fe38b7c-9bb8-4c7f-b2a0-32ac7ba4f90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sastrawi\n",
            "Successfully installed sastrawi-1.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_stem(text):\n",
        "    # Tokenize the text into words\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords (common words that do not carry much meaning)\n",
        "    stop_words = set(stopwords.words('indonesian'))\n",
        "    words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    # Perform stemming using the Sastrawi stemmer\n",
        "    base_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    return ' '.join(base_words)"
      ],
      "metadata": {
        "id": "k_Xdjs8BJ_9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['perihal'] = df['perihal'].apply(lambda x: tokenize_and_stem(x) if isinstance(x, str) else '')\n",
        "\n",
        "# Print the DataFrame with the base words extracted from 'Base_Words'\n",
        "print(df['perihal'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnkgleAsKEqI",
        "outputId": "4adf2f9b-6238-41bd-9daa-a69804cc9dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      financial guarantee beasiswa aichi university ...\n",
            "4              janji tugas ajar uny dyna herlina suwarto\n",
            "5      surat rekomendasi tugas ajar nottingham univer...\n",
            "6            laksana program ppg jabat subsidi angkat th\n",
            "8      janji kerjasama badan pegawai diklat kab kulon...\n",
            "                             ...                        \n",
            "146    st laksana bersih lingkung ruang asrama mahasi...\n",
            "147            mohon ganti biaya daftar an sigit raharjo\n",
            "148            mohon ganti biaya daftar an yarso nurbowo\n",
            "150    damping awas kendali izin damping sipata sumur...\n",
            "152                          lapor volumedebit air tanah\n",
            "Name: perihal, Length: 123, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag Of Word"
      ],
      "metadata": {
        "id": "ZvW1ANENKKN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLe1zwx4KL45",
        "outputId": "e4ae9209-db2b-469c-8319-ef0f31de75ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with empty or NaN 'perihal'\n",
        "df = df.dropna(subset=['perihal'])\n",
        "\n",
        "# Filter out rows where 'perihal' is empty or NaN\n",
        "df = df[df['perihal'].notna() & (df['perihal'] != '')]\n",
        "\n",
        "# Create the CountVectorizer only for 'perihal' column\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the 'perihal' column to create the BoW matrix\n",
        "bow_matrix = vectorizer.fit_transform(df['perihal'])\n",
        "\n",
        "# Convert the BoW matrix to a DataFrame\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Show the resulting DataFrame with Bag of Words representation for 'Base_Words' only\n",
        "print(bow_df)\n",
        "print(bow_df.loc[0].to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IXEi83eKWds",
        "outputId": "4d828d6a-38b1-463d-afa6-7f15e751ec8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     1st  aceh  administrasi  aichi  air  ajar  aju  akademik  ambil  an  ...  \\\n",
            "0      0     0             0      1    0     0    0         0      0   0  ...   \n",
            "1      0     0             0      0    0     1    0         0      0   0  ...   \n",
            "2      0     0             0      0    0     1    0         0      0   0  ...   \n",
            "3      0     0             0      0    0     0    0         0      0   0  ...   \n",
            "4      0     0             0      0    0     0    0         0      0   0  ...   \n",
            "..   ...   ...           ...    ...  ...   ...  ...       ...    ...  ..  ...   \n",
            "118    0     0             0      0    0     0    0         0      0   0  ...   \n",
            "119    0     0             0      0    0     0    0         0      0   1  ...   \n",
            "120    0     0             0      0    0     0    0         0      0   1  ...   \n",
            "121    0     0             0      0    0     0    0         0      0   0  ...   \n",
            "122    0     0             0      0    1     0    0         0      0   0  ...   \n",
            "\n",
            "     vokasi  volumedebit  wakil  wates  wedomartani  workshop  yarso  \\\n",
            "0         0            0      0      0            0         0      0   \n",
            "1         0            0      0      0            0         0      0   \n",
            "2         0            0      0      0            0         0      0   \n",
            "3         0            0      0      0            0         0      0   \n",
            "4         0            0      0      0            0         0      0   \n",
            "..      ...          ...    ...    ...          ...       ...    ...   \n",
            "118       0            0      0      0            1         0      0   \n",
            "119       0            0      0      0            0         0      0   \n",
            "120       0            0      0      0            0         0      1   \n",
            "121       0            0      0      0            0         0      0   \n",
            "122       0            1      0      0            0         0      0   \n",
            "\n",
            "     yogyakarta  yuli  yunike  \n",
            "0             0     0       0  \n",
            "1             0     0       0  \n",
            "2             0     0       0  \n",
            "3             0     0       0  \n",
            "4             0     0       0  \n",
            "..          ...   ...     ...  \n",
            "118           0     0       0  \n",
            "119           0     0       0  \n",
            "120           0     0       0  \n",
            "121           0     0       0  \n",
            "122           0     0       0  \n",
            "\n",
            "[123 rows x 381 columns]\n",
            "{'1st': 0, 'aceh': 0, 'administrasi': 0, 'aichi': 1, 'air': 0, 'ajar': 0, 'aju': 0, 'akademik': 0, 'ambil': 0, 'an': 0, 'analisis': 0, 'and': 0, 'andal': 0, 'angkat': 0, 'aprilia': 0, 'arin': 0, 'arsip': 0, 'arts': 0, 'asesmen': 0, 'aset': 0, 'asrama': 0, 'atas': 0, 'atur': 0, 'audit': 0, 'aunseednet': 0, 'automotive': 0, 'awas': 0, 'badan': 0, 'bahas': 0, 'bangka': 0, 'bangun': 0, 'bantu': 0, 'barat': 0, 'barito': 0, 'beasiswa': 1, 'beban': 0, 'belitung': 0, 'beri': 0, 'berkas': 0, 'bersih': 0, 'biaya': 0, 'bidang': 0, 'bimtek': 0, 'bina': 0, 'bmn': 0, 'boptn': 0, 'bor': 0, 'bpd': 0, 'bpi': 0, 'buat': 0, 'building': 0, 'bupk': 0, 'business': 0, 'cahyo': 0, 'cair': 0, 'center': 0, 'cepat': 0, 'childhood': 0, 'conference': 0, 'coret': 0, 'counseling': 0, 'covid': 0, 'creative': 0, 'dab': 0, 'daftar': 0, 'damping': 0, 'dana': 0, 'data': 0, 'daya': 0, 'didik': 0, 'dikbud': 0, 'diklat': 0, 'dikpora': 0, 'dinas': 0, 'direktorat': 0, 'diri': 0, 'dirjen': 0, 'diy': 0, 'dlam': 0, 'doktor': 0, 'doktoral': 0, 'dokumen': 0, 'dosen': 0, 'draf': 0, 'dukung': 0, 'dyna': 0, 'early': 0, 'economic': 0, 'education': 1, 'eksiting': 0, 'electric': 0, 'elementary': 0, 'elinvo': 0, 'enim': 0, 'era': 0, 'erma': 0, 'evaluasi': 0, 'evluasi': 0, 'facing': 0, 'fadhli': 0, 'fakultas': 0, 'fgd': 0, 'final': 0, 'financial': 1, 'fitria': 0, 'form': 0, 'fungsional': 0, 'gambar': 0, 'ganti': 0, 'gedung': 0, 'gedungelectronics': 0, 'general': 0, 'giat': 0, 'going': 0, 'guarantee': 1, 'guidance': 0, 'gunung': 0, 'gunungkidul': 0, 'guru': 0, 'hadap': 0, 'hak': 0, 'hasil': 0, 'health': 0, 'herlina': 0, 'ice': 0, 'iceelinvo': 0, 'idb': 0, 'ijin': 0, 'ikut': 0, 'ilmiah': 0, 'imb': 0, 'in': 0, 'innovative': 0, 'instalasi': 0, 'instansi': 0, 'integrated': 0, 'international': 0, 'internet': 0, 'ippt': 0, 'irjen': 0, 'isdb': 0, 'isi': 0, 'iso': 0, 'izin': 0, 'jabat': 0, 'janji': 0, 'japan': 1, 'jombang': 0, 'juniarti': 0, 'kab': 0, 'kabupaten': 0, 'kait': 0, 'kaji': 0, 'kala': 0, 'kampus': 0, 'kasih': 0, 'kelai': 0, 'kelola': 0, 'kelompok': 0, 'kembang': 0, 'kemenag': 0, 'kemendikbud': 0, 'kemendikbudristek': 0, 'kemenkeu': 0, 'kendali': 0, 'kepahiang': 0, 'kepala': 0, 'kerja': 0, 'kerjasama': 0, 'kidul': 0, 'kipk': 0, 'kkpr': 0, 'knb': 0, 'kolom': 0, 'komitmen': 0, 'kompetensi': 0, 'kondisi': 0, 'konsultan': 0, 'konsultasi': 0, 'kontrak': 0, 'koordinasi': 0, 'kualitas': 0, 'kuasa': 0, 'kuliah': 0, 'kulon': 0, 'kumpul': 0, 'kusumawardani': 0, 'laboratorium': 0, 'laboratory': 0, 'laksana': 0, 'langkah2': 0, 'language': 0, 'lanjjutanongoing': 0, 'lanjutanon': 0, 'lapor': 0, 'latih': 0, 'layan': 0, 'lecture': 0, 'letter': 0, 'library': 0, 'lingkung': 0, 'listrik': 0, 'literature': 0, 'loan': 0, 'lomba': 0, 'lpdp': 0, 'lppdp': 0, 'lurah': 0, 'machine': 0, 'mahasiswa': 0, 'manajemen': 0, 'manfaat': 0, 'masyarakatpeningkatan': 0, 'materi': 0, 'mathematic': 0, 'mental': 0, 'mohon': 0, 'monitoring': 0, 'mou': 0, 'muara': 0, 'narasumber': 0, 'natural': 0, 'negeri': 0, 'new': 0, 'non': 0, 'normal': 0, 'nota': 0, 'nottingham': 0, 'nurbowo': 0, 'nurmalasari': 0, 'nyata': 0, 'of': 1, 'on': 0, 'paham': 0, 'pakai': 0, 'paket': 0, 'pandemic': 0, 'panjang': 0, 'pasang': 0, 'pascasarjana': 0, 'pbg': 0, 'pegawai': 0, 'pembahsan': 0, 'pemkab': 0, 'penandatanganan': 0, 'pendidikanpenelitianpengabdian': 0, 'pengambilanpengusahaan': 0, 'pensertifikatan': 0, 'penugasanpengelolaan': 0, 'penyelengaraan': 0, 'perencanaankeuanganubmnsa': 0, 'performance': 0, 'perijinan': 0, 'periksa': 0, 'perngurusan': 0, 'pertanggungjawaban': 0, 'physical': 0, 'pidie': 0, 'pilih': 0, 'pimpin': 0, 'pinjam': 0, 'pns': 0, 'ppg': 0, 'ppm': 0, 'pps': 0, 'ppsaunseednet': 0, 'pranesti': 0, 'profesi': 0, 'progo': 0, 'program': 0, 'proses': 0, 'prov': 0, 'pt': 0, 'publikasi': 0, 'raharjo': 0, 'rahmat': 0, 'rakor': 0, 'rangka': 0, 'rangkai': 0, 'rapat': 0, 'recommendation': 0, 'rekomendasi': 0, 'rektor': 0, 'rektorat': 0, 'riau': 0, 'rincian': 0, 'ristek': 0, 'rizky': 0, 'rkbn': 0, 'ruang': 0, 'sarjana': 0, 'sc': 0, 'school': 0, 'science': 0, 'sdm': 0, 'seleksi': 0, 'selenggara': 0, 'selesai': 0, 'seminar': 0, 'september': 0, 'serap': 0, 'serifikat': 0, 'serta': 0, 'sertifikat': 0, 'sesuai': 0, 'sewa': 0, 'sigit': 0, 'silaturahmi': 0, 'sipa': 0, 'sipat': 0, 'sipata': 0, 'sleman': 0, 'slf': 0, 'sni': 0, 'social': 0, 'sosialisasi': 0, 'spiritual': 0, 'sport': 0, 'st': 0, 'stage': 0, 'status': 0, 'struktur': 0, 'subsidi': 0, 'suket': 0, 'sumur': 0, 'surat': 0, 'surtat': 0, 'susun': 0, 'suwarto': 0, 'ta': 0, 'tahap': 0, 'tanah': 0, 'tanggung': 0, 'tata': 0, 'teknik': 0, 'teknis': 0, 'teknologi': 0, 'temu': 0, 'tenaga': 0, 'tender': 0, 'tentu': 0, 'terap': 0, 'terima': 0, 'th': 0, 'the': 0, 'tika': 0, 'tim': 0, 'timur': 0, 'tindak': 0, 'tnd': 0, 'training': 0, 'tubel': 0, 'tugas': 0, 'tuju': 0, 'uang': 0, 'ucap': 0, 'uji': 0, 'uklupl': 0, 'ukm': 0, 'ukur': 0, 'undang': 0, 'universitas': 0, 'university': 1, 'uny': 0, 'urus': 0, 'usaha': 0, 'usul': 0, 'utama': 0, 'utomo': 0, 'virtual': 0, 'visitasi': 0, 'vokasi': 0, 'volumedebit': 0, 'wakil': 0, 'wates': 0, 'wedomartani': 0, 'workshop': 0, 'yarso': 0, 'yogyakarta': 0, 'yuli': 0, 'yunike': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING"
      ],
      "metadata": {
        "id": "UnZMii0kKeHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique values in the 'kelompok' column\n",
        "unique_kelompok = df['kelompok'].unique()\n",
        "\n",
        "# Show the unique values\n",
        "print(unique_kelompok)\n",
        "print(len(unique_kelompok))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJgjIi4xKfDV",
        "outputId": "bec0b915-5ae6-4054-c582-e6ed72a88b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 624  932  950 1192  981 1085  980 1587]\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load your dataset and preprocess it as needed\n",
        "# Assuming you have 'bow_df' as your input features and 'df' as the DataFrame containing 'kelompok' as target labels\n",
        "X = bow_df.values\n",
        "y = df['kelompok'].values\n",
        "\n",
        "# Define the number of neurons in the hidden layer\n",
        "hidden_units = 100\n",
        "\n",
        "# Define the number of output classes\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Initialize lists to store the accuracy for each fold\n",
        "accuracy_scores = []\n",
        "\n",
        "# Create K-Fold Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Create the MLP model\n",
        "model = Sequential()\n",
        "model.add(Dense(hidden_units, activation='relu', input_shape=(X.shape[1],)))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model with optimizer, loss function, and metrics\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Perform K-Fold Cross-Validation\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Perform one-hot encoding on the target labels for training data\n",
        "    encoder = OneHotEncoder()\n",
        "    y_train_one_hot = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
        "    y_test_one_hot = encoder.fit_transform(y_test.reshape(-1, 1)).toarray()\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train_one_hot, epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred_one_hot = model.predict(X_test)\n",
        "    y_pred_labels = np.argmax(y_pred_one_hot, axis=1)\n",
        "\n",
        "    y_test_labels = np.argmax(y_test_one_hot, axis=1)\n",
        "\n",
        "    # Calculate accuracy for the current fold\n",
        "    accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
        "\n",
        "    print(np.argmax(y_test_one_hot, axis=1))\n",
        "    print(y_pred_labels)\n",
        "\n",
        "    print(f\"Fold {fold + 1} - Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "# Calculate and print the average accuracy across all folds\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "print(f\"Average Accuracy: {avg_accuracy:.2f}\")\n",
        "\n",
        "# Save the model to a file\n",
        "model.save('trained_model.h5')\n",
        "\n",
        "# Get the input shape of the model\n",
        "input_shape = model.layers[0].input_shape\n",
        "print(f\"Input shape: {input_shape}\")\n",
        "\n",
        "# Now, print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mLvas07Kqtf",
        "outputId": "b9e9e3e5-c13b-46ea-820c-a95d1eddd618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 1s 4ms/step - loss: 2.0598 - accuracy: 0.1735\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.9343 - accuracy: 0.3673\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.8314 - accuracy: 0.6327\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.7384 - accuracy: 0.7755\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.6464 - accuracy: 0.8367\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.5590 - accuracy: 0.8571\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.4770 - accuracy: 0.8878\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3971 - accuracy: 0.9082\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3220 - accuracy: 0.9286\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2503 - accuracy: 0.9184\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1797 - accuracy: 0.9184\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1137 - accuracy: 0.9286\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0527 - accuracy: 0.9286\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9938 - accuracy: 0.9388\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9391 - accuracy: 0.9388\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8859 - accuracy: 0.9388\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8374 - accuracy: 0.9388\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7900 - accuracy: 0.9388\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7480 - accuracy: 0.9490\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.9490\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "[0 1 2 2 1 1 1 1 3 5 1 0 2 2 3 2 5 4 2 6 6 6 3 2 2]\n",
            "[3 1 2 2 1 1 1 1 3 6 1 0 2 2 3 2 6 3 2 3 3 1 3 2 2]\n",
            "Fold 1 - Accuracy: 0.72\n",
            "Epoch 1/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7823 - accuracy: 0.8980\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7340 - accuracy: 0.9082\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.9184\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.9184\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.9286\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.9286\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.9388\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.9388\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.9388\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.9388\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.9490\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.9592\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.9592\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.9592\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.9592\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.9592\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3101 - accuracy: 0.9592\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2965 - accuracy: 0.9694\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2849 - accuracy: 0.9694\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.9694\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "[2 4 0 3 1 1 1 1 1 3 5 5 5 5 5 5 2 1 3 6 6 6 6 5 2]\n",
            "[2 5 0 3 1 1 1 1 1 3 6 6 6 6 6 6 2 1 3 7 7 7 7 6 2]\n",
            "Fold 2 - Accuracy: 0.52\n",
            "Epoch 1/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2597 - accuracy: 0.9898\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2466 - accuracy: 0.9898\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2331 - accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2201 - accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2072 - accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1952 - accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1838 - accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1640 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1553 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1346 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1135 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1090 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1002 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "[1 6 4 4 0 3 3 2 1 2 2 5 5 6 2 5 6 6 2 2 4 3 2 2 2]\n",
            "[1 6 3 3 0 3 3 2 1 2 2 5 5 6 2 2 6 6 2 2 4 3 2 2 2]\n",
            "Fold 3 - Accuracy: 0.88\n",
            "Epoch 1/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1652 - accuracy: 0.9697\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9697\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9798\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9798\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1418 - accuracy: 0.9798\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9798\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9798\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.9798\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9798\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1176 - accuracy: 0.9798\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.9798\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1103 - accuracy: 0.9798\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.9798\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.9798\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9798\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9798\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 0.9798\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0918 - accuracy: 0.9798\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0891 - accuracy: 0.9798\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9798\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[1 3 0 2 5 2 1 0 2 4 2 2 2 3 7 7 7 7 2 2 2 2 2 6]\n",
            "[1 3 0 2 5 2 1 0 2 4 2 2 2 3 7 7 7 7 2 2 2 2 2 6]\n",
            "Fold 4 - Accuracy: 1.00\n",
            "Epoch 1/20\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0789 - accuracy: 0.9798\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0765 - accuracy: 0.9798\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9798\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0716 - accuracy: 0.9798\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9798\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9798\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9899\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.9899\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9899\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9899\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9899\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0460 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0444 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0410 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[1 0 3 3 4 1 1 4 1 1 4 5 5 6 6 3 3 3 3 5 2 2 2 2]\n",
            "[1 0 3 3 5 1 1 5 1 1 5 6 6 7 7 3 3 3 3 6 2 2 2 2]\n",
            "Fold 5 - Accuracy: 0.67\n",
            "Average Accuracy: nan\n",
            "Input shape: (None, 381)\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_80 (Dense)            (None, 100)               38200     \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 8)                 808       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39,008\n",
            "Trainable params: 39,008\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load model and predict"
      ],
      "metadata": {
        "id": "pif2pXTUK0KI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/trained_model.h5')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "import pandas as pd\n",
        "# Sample with 'perihal' column\n",
        "perihal_data = {\n",
        "    'perihal': [\n",
        "        'surat undangan rapat bidang ii'\n",
        "    ]\n",
        "}\n",
        "\n",
        "new_data = pd.DataFrame(perihal_data)\n",
        "\n",
        "# Convert 'perihal' data to lowercase\n",
        "new_data['perihal'] = new_data['perihal'].str.lower()\n",
        "\n",
        "# clearng text\n",
        "new_data['perihal'] = new_data['perihal'].apply(clear_text)\n",
        "# print(new_data['perihal'])\n",
        "\n",
        "\n",
        "# base words\n",
        "new_data['perihal'] = new_data['perihal'].apply(lambda x: tokenize_and_stem(x) if isinstance(x, str) else '')\n",
        "\n",
        "# Print the DataFrame with the base words extracted from 'Base_Words'\n",
        "print(new_data['perihal'])\n",
        "\n",
        "new_data_bow = vectorizer.transform(new_data['perihal'])\n",
        "new_data_bow_df = pd.DataFrame(new_data_bow.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "# print(new_data_bow_df)\n",
        "\n",
        "predictions = model.predict(new_data_bow_df)\n",
        "\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "print(predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_WroqX6K049",
        "outputId": "facea8b0-f128-4f2e-e055-273aead87cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_80 (Dense)            (None, 100)               38200     \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 8)                 808       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39,008\n",
            "Trainable params: 39,008\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "0    surat undang rapat bidang\n",
            "Name: perihal, dtype: object\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "[4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map predicted class indices to the actual label names (kelompok)\n",
        "predicted_kelompok = [unique_kelompok[label_index] for label_index in predicted_labels]\n",
        "\n",
        "print(predictions)\n",
        "\n",
        "# Print the predicted kelompok\n",
        "print(predicted_kelompok)\n",
        "\n",
        "selected_kode = df.loc[df['kelompok'].isin(predicted_kelompok), 'kode']\n",
        "first_selected_kode = selected_kode.iloc[0] if not selected_kode.empty else None\n",
        "\n",
        "print(first_selected_kode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oyfUiMDK8H3",
        "outputId": "11e13f80-b565-448b-87eb-c22a2cb6ad37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0052394  0.00498233 0.00728563 0.0616226  0.8714806  0.01059833\n",
            "  0.02753395 0.01125717]]\n",
            "[981]\n",
            "TU.01.01 - Rapat Pimpinan (Undangan, Daftar hadir, Notula)\n"
          ]
        }
      ]
    }
  ]
}